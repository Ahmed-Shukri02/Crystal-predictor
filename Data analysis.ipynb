{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fff4ab24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>In literature</th>\n",
       "      <th>v(A)</th>\n",
       "      <th>v(B)</th>\n",
       "      <th>r(AXII)(Å)</th>\n",
       "      <th>r(AVI)(Å)</th>\n",
       "      <th>r(BVI)(Å)</th>\n",
       "      <th>EN(A)</th>\n",
       "      <th>EN(B)</th>\n",
       "      <th>l(A-O)(Å)</th>\n",
       "      <th>l(B-O)(Å)</th>\n",
       "      <th>ΔENR</th>\n",
       "      <th>tG</th>\n",
       "      <th>τ</th>\n",
       "      <th>μ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.248000</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.93</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.488353</td>\n",
       "      <td>-2.565071</td>\n",
       "      <td>0.758259</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.678571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.61</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.892894</td>\n",
       "      <td>-1.846714</td>\n",
       "      <td>0.918510</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.385714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.932227</td>\n",
       "      <td>-1.577429</td>\n",
       "      <td>0.928078</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.371429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.10</td>\n",
       "      <td>2.54</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.313698</td>\n",
       "      <td>-2.279786</td>\n",
       "      <td>0.764768</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.12</td>\n",
       "      <td>2.178342</td>\n",
       "      <td>2.268642</td>\n",
       "      <td>-2.022750</td>\n",
       "      <td>0.576276</td>\n",
       "      <td>-3.959996282</td>\n",
       "      <td>0.621429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.88</td>\n",
       "      <td>2.178342</td>\n",
       "      <td>1.930311</td>\n",
       "      <td>-1.255821</td>\n",
       "      <td>0.677797</td>\n",
       "      <td>-11.73628918</td>\n",
       "      <td>0.378571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.66</td>\n",
       "      <td>2.178342</td>\n",
       "      <td>1.960053</td>\n",
       "      <td>-1.329107</td>\n",
       "      <td>0.670845</td>\n",
       "      <td>-9.609017798</td>\n",
       "      <td>0.392857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1.609165</td>\n",
       "      <td>2.266492</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.67</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.79</td>\n",
       "      <td>2.178342</td>\n",
       "      <td>3.009747</td>\n",
       "      <td>-3.592929</td>\n",
       "      <td>0.426107</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>1.192857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1.609165</td>\n",
       "      <td>2.266492</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.57</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.178342</td>\n",
       "      <td>2.005574</td>\n",
       "      <td>-1.537071</td>\n",
       "      <td>0.628917</td>\n",
       "      <td>2.503861</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B  In literature      v(A)      v(B)  r(AXII)(Å)  r(AVI)(Å)  \\\n",
       "0    0   0              0         0         0        1.12       1.12   \n",
       "1    0   1              0         0         0        1.12       1.12   \n",
       "2    0   2              0         0         0        1.12       1.12   \n",
       "3    0   3              0         0         0        1.12       1.12   \n",
       "4    0   4              0         0         0        1.12       1.12   \n",
       "..  ..  ..            ...       ...       ...         ...        ...   \n",
       "522  7  11              0         2         4        0.45       0.45   \n",
       "523  7  12              0         2         4        0.45       0.45   \n",
       "524  7  13              0         2         4        0.45       0.45   \n",
       "525  7  14              0  1.609165  2.266492        0.45       0.45   \n",
       "526  7  15              0  1.609165  2.266492        0.45       0.45   \n",
       "\n",
       "     r(BVI)(Å)  EN(A)  EN(B)  l(A-O)(Å)  l(B-O)(Å)      ΔENR        tG  \\\n",
       "0         1.12   1.10   1.10   0.000000   0.000000 -3.248000  0.707107   \n",
       "1         0.95   1.10   1.93   0.000000   2.488353 -2.565071  0.758259   \n",
       "2         0.54   1.10   1.61   0.000000   1.892894 -1.846714  0.918510   \n",
       "3         0.52   1.10   2.18   0.000000   1.932227 -1.577429  0.928078   \n",
       "4         0.93   1.10   2.54   0.000000   2.313698 -2.279786  0.764768   \n",
       "..         ...    ...    ...        ...        ...       ...       ...   \n",
       "522       0.87   1.57   1.12   2.178342   2.268642 -2.022750  0.576276   \n",
       "523       0.53   1.57   1.88   2.178342   1.930311 -1.255821  0.677797   \n",
       "524       0.55   1.57   1.66   2.178342   1.960053 -1.329107  0.670845   \n",
       "525       1.67   1.57   0.79   2.178342   3.009747 -3.592929  0.426107   \n",
       "526       0.68   1.57   1.90   2.178342   2.005574 -1.537071  0.628917   \n",
       "\n",
       "                τ         μ  \n",
       "0        2.503861  0.800000  \n",
       "1        2.503861  0.678571  \n",
       "2        2.503861  0.385714  \n",
       "3        2.503861  0.371429  \n",
       "4        2.503861  0.664286  \n",
       "..            ...       ...  \n",
       "522  -3.959996282  0.621429  \n",
       "523  -11.73628918  0.378571  \n",
       "524  -9.609017798  0.392857  \n",
       "525      2.503861  1.192857  \n",
       "526      2.503861  0.485714  \n",
       "\n",
       "[527 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, file_directory: str, not_number: list, filetype: str = \"csv\", \n",
    "                 encodetype: str = \"label\", replaceNAN: bool = True):\n",
    "        \"\"\"Init function\n",
    "            Inputs: \n",
    "            file_directory: directory of the file relative to script.\n",
    "            filetype: type of file to be imported (defaulted as csv).\n",
    "            not_number: map of columns -> bool based on if the values of the column are not numbers.\n",
    "            encodetype: type of encoder to be used (ONLY onehot or label). Defaulted to label\n",
    "            replace: true if all N/A values should be replaced by the mean of the column, false if row\n",
    "            containing N/A should be ommitted (defaulted to true).\n",
    "            \n",
    "            Returns: None\"\"\"\n",
    "        \n",
    "        # add attributes\n",
    "        self.dir = file_directory\n",
    "        self.boolmap = not_number\n",
    "        self.filetype = filetype\n",
    "        self.replaceNAN = replaceNAN\n",
    "        \n",
    "        # make sure encodetype is either onehot or label\n",
    "        check = (encodetype == \"onehot\" or encodetype == \"label\")\n",
    "        assert check, f\"Unexpected encode type '{encodetype}'. Preprocessor only takes onehot or label encoding\"\n",
    "        \n",
    "        #add encoder attribute\n",
    "        self.encodetype = encodetype\n",
    "        \n",
    "\n",
    "    def Process(self) -> pd.DataFrame:\n",
    "        \"\"\"Calls all other functions within class and runs until a \n",
    "            clean, encoded Dataframe is returned to the user\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__)\n",
    "            \n",
    "            Returns: pandas dataframe of fully preprocessed data\"\"\"\n",
    "        \n",
    "        # first we import the file:\n",
    "        raw_data = self.ImportAsDf()\n",
    "        # we then clean the data:\n",
    "        clean_data, worded_columns = self.CleanData(raw_data)\n",
    "        # finally, we encode the clean data\n",
    "        final = self.Encode(clean_data, worded_columns)\n",
    "        \n",
    "        return final\n",
    "    \n",
    "    \n",
    "    def ImportAsDf(self) -> pd.DataFrame:\n",
    "        \"\"\"Grabs file and imports it as a pandas Dataframe.\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__).\n",
    "\n",
    "            Returns: pandas dataframe of the raw data\"\"\"\n",
    "\n",
    "        if(self.filetype == \"csv\"):\n",
    "            return pd.read_csv(self.dir)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def CleanData(self, data: pd.DataFrame) -> tuple:\n",
    "        \"\"\"Goes through the data and removes/replaces any N/A values, as well\n",
    "           returning any worded columns to to be encoded.\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__).\n",
    "            data: data to be cleaned. \n",
    "\n",
    "            Returns: tuple: \n",
    "                   0: pandas dataframe of the cleaned data\n",
    "                   1: list of all worded columns to be encoded\"\"\"\n",
    "\n",
    "        #reset index of data \n",
    "        data = data.reset_index(drop=True)\n",
    "        #remove unnecessary columns\n",
    "        data = data.drop(\"Compound\", axis=1)\n",
    "        #replace all \"-\" with NAN\n",
    "        data = data.replace(\"-\", np.nan)\n",
    "\n",
    "        #get two lists of columns split on whether their values are numbers or not:\n",
    "        numerated_columns = [data.columns[i] for i in range(len(data.columns)) if self.boolmap[i] == False]\n",
    "        worded_columns = [data.columns[i] for i in range(len(data.columns)) if self.boolmap[i] == True]\n",
    "\n",
    "        # we first search through worded columns and remove row where NA is present, since mean method will not work:\n",
    "        for column in worded_columns:\n",
    "            removal_list=[]\n",
    "            \n",
    "            # go through every value in worded column\n",
    "            for i, value in enumerate(data[column]):\n",
    "                \n",
    "                # add row index of each occurance of NAN\n",
    "                if(pd.isna(value)): removal_list.append(i)\n",
    "            \n",
    "            # remove once iteration is complete to avoid issues with index i:\n",
    "            data.drop(removal_list, inplace=True)\n",
    "\n",
    "        \n",
    "        # we then search through numbered columns, and either replace NA with a mean or remove column    \n",
    "        if(self.replaceNAN== True):\n",
    "            for column in numerated_columns:\n",
    "                #find mean of column (convert all values in columns to floats before averaging)\n",
    "                column_mean = data[column].apply(lambda x: float(x)).mean(skipna= True)\n",
    "                \n",
    "                #replace na values on column with mean\n",
    "                data[column] = data[column].apply(lambda x: column_mean if pd.isna(x) == True else x)\n",
    "            \n",
    "            return (data.reset_index(drop=True), worded_columns)\n",
    "        \n",
    "        \n",
    "        else: # remove NA values if repalce is set to false:\n",
    "            return (data.dropna().reset_index(drop=True), worded_columns)\n",
    "\n",
    "    \n",
    "    def Encode(self, data: pd.DataFrame, encode_columns: list) -> pd.DataFrame:\n",
    "        \"\"\"Encodes columns either using a label encoder or a onehot encoder.\n",
    "            Inputs:\n",
    "            self: contains attributes (refer to notes at __init__)\n",
    "            data: data to be encoded.\n",
    "            encode_columns: list of columns by label to be encoded\n",
    "            \n",
    "            Returns:\n",
    "            Pandas dataframe of the encoded data\"\"\"\n",
    "        \n",
    "        # exclude final column from being encoded since it is the dependant variable\n",
    "        encode_columns = encode_columns[:-1]\n",
    "        \n",
    "        #check if onehot or label encoder is being used\n",
    "        if(self.encodetype == \"onehot\"):\n",
    "            for column in encode_columns:\n",
    "                # grab a list of distinct categories\n",
    "                categories = sorted(set(data[column]))\n",
    "                \n",
    "                # go through each category and make a new column with binary values 0 or 1\n",
    "                for category in categories:\n",
    "                    data[f\"{column}_{category}\"] = data[column].apply(lambda x: 1 if x == category else 0)\n",
    "                \n",
    "                #drop column\n",
    "                data.drop(column, axis=1, inplace = True)\n",
    "                \n",
    "            return data\n",
    "        \n",
    "        else: # must be label due to previous assertion\n",
    "            for column in encode_columns:\n",
    "                # grab a list of distinct categories\n",
    "                categories = sorted(set(data[column]))\n",
    "                \n",
    "                # map these categories to integers:\n",
    "                category_map = {categories[i] : i for i in range(len(categories))}\n",
    "                \n",
    "                # apply value using the map\n",
    "                data[column] = data[column].apply(lambda x: category_map[x])\n",
    "            \n",
    "            return data\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "def SplitData(data: pd.DataFrame, train_ratio: float = 0.1) -> tuple:\n",
    "    \"\"\"Splits data into train and test samples\n",
    "        Inputs:\n",
    "        data: data to be split\n",
    "        train_ratio: the ratio of train to test array size for the data.\n",
    "        (defaulted to 10% train with 90% test data)\n",
    "        \n",
    "        Returns: tuple:\n",
    "                 0: pandas DataFrame of train data for independent variables.\n",
    "                 1: pandas DataFrame of test data for independent variables.\n",
    "                 2: pandas Series of train data for dependent variable.\n",
    "                 3: pandas Series of test data for dependent variable.\"\"\"\n",
    "    \n",
    "    # find index where data should be split\n",
    "    index = int(train_ratio * len(data.index))\n",
    "    \n",
    "    # Make a list of dependent and independant variables:\n",
    "    X_columns = list(data.columns)\n",
    "    y_columns = X_columns.pop(-1)\n",
    "    \n",
    "    # split X and y data into test and training data for each\n",
    "    X_train = data[X_columns][:index].reset_index(drop=True)\n",
    "    X_test = data[X_columns][index:].reset_index(drop=True)\n",
    "    y_train = data[y_columns][:index].reset_index(drop=True)\n",
    "    y_test = data[y_columns][index:].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# create boolean map of columns where non-numeric columns are True, excluding items that want to be ignored\n",
    "classmap = [True, True, True, False, False, False, False, False, False,\n",
    "           False, False, False, False, False, False, False, True]\n",
    "\n",
    "file_directory = \"Crystal_structure.csv\"\n",
    "\n",
    "# get preprocessed data\n",
    "clean = Preprocessor(file_directory, classmap, replaceNAN = True).Process()\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = SplitData(clean)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
