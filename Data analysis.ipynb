{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fff4ab24",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>v(A)</th>\n",
       "      <th>v(B)</th>\n",
       "      <th>r(AXII)(Å)</th>\n",
       "      <th>r(AVI)(Å)</th>\n",
       "      <th>r(BVI)(Å)</th>\n",
       "      <th>EN(A)</th>\n",
       "      <th>EN(B)</th>\n",
       "      <th>l(A-O)(Å)</th>\n",
       "      <th>l(B-O)(Å)</th>\n",
       "      <th>ΔENR</th>\n",
       "      <th>tG</th>\n",
       "      <th>τ</th>\n",
       "      <th>μ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449816</td>\n",
       "      <td>0.321123</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.826765</td>\n",
       "      <td>0.591802</td>\n",
       "      <td>0.372063</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.485714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.468571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.628921</td>\n",
       "      <td>0.741155</td>\n",
       "      <td>0.531650</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.192857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>0.794286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.641990</td>\n",
       "      <td>0.797141</td>\n",
       "      <td>0.541178</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.178571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.527950</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.471429</td>\n",
       "      <td>0.177143</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.768735</td>\n",
       "      <td>0.651116</td>\n",
       "      <td>0.378545</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.471429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.188571</td>\n",
       "      <td>0.660068</td>\n",
       "      <td>0.753765</td>\n",
       "      <td>0.704555</td>\n",
       "      <td>0.190835</td>\n",
       "      <td>0.614032</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.622857</td>\n",
       "      <td>0.660068</td>\n",
       "      <td>0.641353</td>\n",
       "      <td>0.864006</td>\n",
       "      <td>0.291934</td>\n",
       "      <td>0.604344</td>\n",
       "      <td>0.185714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.497143</td>\n",
       "      <td>0.660068</td>\n",
       "      <td>0.651235</td>\n",
       "      <td>0.848769</td>\n",
       "      <td>0.285011</td>\n",
       "      <td>0.606994</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>0.321833</td>\n",
       "      <td>0.453298</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.660068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>0.041287</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>0.321833</td>\n",
       "      <td>0.453298</td>\n",
       "      <td>0.111801</td>\n",
       "      <td>0.128571</td>\n",
       "      <td>0.292857</td>\n",
       "      <td>0.445714</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.660068</td>\n",
       "      <td>0.666360</td>\n",
       "      <td>0.805532</td>\n",
       "      <td>0.243257</td>\n",
       "      <td>0.622084</td>\n",
       "      <td>0.292857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     A   B      v(A)      v(B)  r(AXII)(Å)  r(AVI)(Å)  r(BVI)(Å)     EN(A)  \\\n",
       "0    0   0  0.000000  0.000000    0.527950   0.607143   0.607143  0.177143   \n",
       "1    0   1  0.000000  0.000000    0.527950   0.607143   0.485714  0.177143   \n",
       "2    0   2  0.000000  0.000000    0.527950   0.607143   0.192857  0.177143   \n",
       "3    0   3  0.000000  0.000000    0.527950   0.607143   0.178571  0.177143   \n",
       "4    0   4  0.000000  0.000000    0.527950   0.607143   0.471429  0.177143   \n",
       "..  ..  ..       ...       ...         ...        ...        ...       ...   \n",
       "522  7  11  0.400000  0.800000    0.111801   0.128571   0.428571  0.445714   \n",
       "523  7  12  0.400000  0.800000    0.111801   0.128571   0.185714  0.445714   \n",
       "524  7  13  0.400000  0.800000    0.111801   0.128571   0.200000  0.445714   \n",
       "525  7  14  0.321833  0.453298    0.111801   0.128571   1.000000  0.445714   \n",
       "526  7  15  0.321833  0.453298    0.111801   0.128571   0.292857  0.445714   \n",
       "\n",
       "        EN(B)  l(A-O)(Å)  l(B-O)(Å)      ΔENR        tG         τ         μ  \n",
       "0    0.177143   0.000000   0.000000  0.449816  0.321123  0.622084  0.607143  \n",
       "1    0.651429   0.000000   0.826765  0.591802  0.372063  0.622084  0.485714  \n",
       "2    0.468571   0.000000   0.628921  0.741155  0.531650  0.622084  0.192857  \n",
       "3    0.794286   0.000000   0.641990  0.797141  0.541178  0.622084  0.178571  \n",
       "4    1.000000   0.000000   0.768735  0.651116  0.378545  0.622084  0.471429  \n",
       "..        ...        ...        ...       ...       ...       ...       ...  \n",
       "522  0.188571   0.660068   0.753765  0.704555  0.190835  0.614032  0.428571  \n",
       "523  0.622857   0.660068   0.641353  0.864006  0.291934  0.604344  0.185714  \n",
       "524  0.497143   0.660068   0.651235  0.848769  0.285011  0.606994  0.200000  \n",
       "525  0.000000   0.660068   1.000000  0.378103  0.041287  0.622084  1.000000  \n",
       "526  0.634286   0.660068   0.666360  0.805532  0.243257  0.622084  0.292857  \n",
       "\n",
       "[527 rows x 15 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "\n",
    "class Preprocessor():\n",
    "    def __init__(self, file_directory: str, not_number: list, filetype: str = \"csv\", \n",
    "                 encodetype: str = \"label\", useScaler: bool = False, scaletype: str = \"minmax\", \n",
    "                 replaceNAN: bool = True):\n",
    "        \"\"\"Init function\n",
    "            Inputs: \n",
    "            file_directory: directory of the file relative to script.\n",
    "            filetype: type of file to be imported (defaulted as csv).\n",
    "            not_number: map of columns -> bool based on if the values of the column are not numbers.\n",
    "            encodetype: type of encoder to be used (ONLY onehot or label). Defaulted to label\n",
    "            replace: true if all N/A values should be replaced by the mean of the column, false if row\n",
    "            containing N/A should be ommitted (defaulted to true).\n",
    "            \n",
    "            Returns: None\"\"\"\n",
    "        \n",
    "        # add attributes\n",
    "        self.dir = file_directory\n",
    "        self.boolmap = not_number\n",
    "        self.filetype = filetype\n",
    "        self.scale = useScaler\n",
    "        self.scaletype = \"minmax\"\n",
    "        self.replaceNAN = replaceNAN\n",
    "        \n",
    "        # make sure encodetype is either onehot or label\n",
    "        encode_check = encodetype in (\"onehot\", \"label\")\n",
    "        assert encode_check, f\"Unexpected encode type '{encodetype}'. Preprocessor only takes onehot or label encoding\"\n",
    "        # add encoder attribute\n",
    "        self.encodetype = encodetype\n",
    "        \n",
    "        # only run if useScaler is true, else scaletype won't be defined.\n",
    "        if(useScaler == True):\n",
    "            # make sure scaletype is either minmax or standard\n",
    "            scale_check = scaletype in (\"minmax\", \"standard\")\n",
    "            assert scale_check, f\"Unexpected scaling type '{scaletype}'. Preprocessor only takes minmax or standard scaling\"\n",
    "            # add scaler attribute\n",
    "            self.scaletype = scaletype\n",
    "        \n",
    "    \n",
    "\n",
    "    def Process(self) -> pd.DataFrame:\n",
    "        \"\"\"Calls all other functions within class and runs until a \n",
    "            clean, encoded Dataframe is returned to the user\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__)\n",
    "            \n",
    "            Returns: pandas dataframe of fully preprocessed data\"\"\"\n",
    "        \n",
    "        # first we import the file:\n",
    "        raw_data = self.ImportAsDf()\n",
    "        # we then clean the data:\n",
    "        clean_data, worded_columns = self.CleanData(raw_data)\n",
    "        # next we encode the necessary worded data:\n",
    "        encoded_data = self.Encode(clean_data, worded_columns)\n",
    "        \n",
    "        # if useScaler is true, scale the non-encoded numerated data:\n",
    "        if(self.scale == True):\n",
    "            # get list of non-encoded numerated columns\n",
    "            numbered_columns = [i for i in encoded_data.columns if i not in worded_columns]\n",
    "            \n",
    "            # scale data\n",
    "            scaled = self.Scale(encoded_data, numbered_columns)\n",
    "            return scaled\n",
    "        \n",
    "        else: return encoded_data\n",
    "    \n",
    "    \n",
    "    def ImportAsDf(self) -> pd.DataFrame:\n",
    "        \"\"\"Grabs file and imports it as a pandas Dataframe.\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__).\n",
    "\n",
    "            Returns: pandas dataframe of the raw data\"\"\"\n",
    "\n",
    "        if(self.filetype == \"csv\"):\n",
    "            return pd.read_csv(self.dir)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    def CleanData(self, data: pd.DataFrame) -> tuple:\n",
    "        \"\"\"Goes through the data and removes/replaces any N/A values, as well\n",
    "           returning any worded columns to to be encoded.\n",
    "            Inputs: \n",
    "            self: contains attributes (refer to notes at __init__).\n",
    "            data: data to be cleaned. \n",
    "\n",
    "            Returns: tuple: \n",
    "                   0: pandas dataframe of the cleaned data\n",
    "                   1: list of all worded columns to be encoded\"\"\"\n",
    "\n",
    "        #reset index of data \n",
    "        data = data.reset_index(drop=True)\n",
    "        #remove unnecessary columns\n",
    "        data = data.drop([\"Compound\", \"In literature\"], axis=1)\n",
    "        #replace all \"-\" with NAN\n",
    "        data = data.replace(\"-\", np.nan)\n",
    "\n",
    "        #get two lists of columns split on whether their values are numbers or not:\n",
    "        numerated_columns = [data.columns[i] for i in range(len(data.columns)) if self.boolmap[i] == False]\n",
    "        worded_columns = [data.columns[i] for i in range(len(data.columns)) if self.boolmap[i] == True]\n",
    "\n",
    "        # we first search through worded columns and remove row where NA is present, since mean method will not work:\n",
    "        for column in worded_columns:\n",
    "            removal_list=[]\n",
    "            \n",
    "            # go through every value in worded column\n",
    "            for i, value in enumerate(data[column]):\n",
    "                \n",
    "                # add row index of each occurance of NAN\n",
    "                if(pd.isna(value)): removal_list.append(i)\n",
    "            \n",
    "            # remove once iteration is complete to avoid issues with index i:\n",
    "            data.drop(removal_list, inplace=True)\n",
    "\n",
    "        \n",
    "        # we then search through numbered columns, and either replace NA with a mean or remove column    \n",
    "        if(self.replaceNAN== True):\n",
    "            for column in numerated_columns:\n",
    "                #find mean of column (convert all values in columns to floats before averaging)\n",
    "                column_mean = data[column].apply(lambda x: float(x)).mean(skipna= True)\n",
    "                \n",
    "                #replace na values on column with mean\n",
    "                data[column] = data[column].apply(lambda x: column_mean if pd.isna(x) == True else x)\n",
    "            \n",
    "            return (data.reset_index(drop=True), worded_columns)\n",
    "        \n",
    "        \n",
    "        else: # remove NA values if repalce is set to false:\n",
    "            return (data.dropna().reset_index(drop=True), worded_columns)\n",
    "\n",
    "    \n",
    "    def Encode(self, data: pd.DataFrame, encode_columns: list) -> pd.DataFrame:\n",
    "        \"\"\"Encodes columns either using a label encoder or a onehot encoder.\n",
    "            Inputs:\n",
    "            self: contains attributes (refer to notes at __init__)\n",
    "            data: data to be encoded.\n",
    "            encode_columns: list of columns by label to be encoded\n",
    "            \n",
    "            Returns:\n",
    "            Pandas dataframe of the encoded data\"\"\"\n",
    "        \n",
    "        # exclude final column from being encoded since it is the dependant variable\n",
    "        #encode_columns = encode_columns[:-1]\n",
    "        \n",
    "        #check if onehot or label encoder is being used\n",
    "        if(self.encodetype == \"onehot\"):\n",
    "            for column in encode_columns:\n",
    "                # grab a list of distinct categories\n",
    "                categories = sorted(set(data[column]))\n",
    "                \n",
    "                # go through each category and make a new column with binary values 0 or 1\n",
    "                for category in categories:\n",
    "                    data[f\"{column}_{category}\"] = data[column].apply(lambda x: 1 if x == category else 0)\n",
    "                \n",
    "                #drop column\n",
    "                data.drop(column, axis=1, inplace = True)\n",
    "                \n",
    "            return data\n",
    "        \n",
    "        else: # must be label due to previous assertion\n",
    "            for column in encode_columns:\n",
    "                # grab a list of distinct categories\n",
    "                categories = sorted(set(data[column]))\n",
    "                \n",
    "                # map these categories to integers:\n",
    "                category_map = {categories[i] : i for i in range(len(categories))}\n",
    "                \n",
    "                # apply value using the map\n",
    "                data[column] = data[column].apply(lambda x: category_map[x])\n",
    "            \n",
    "            return data\n",
    "    \n",
    "    \n",
    "    def Scale(self, data: pd.DataFrame, scale_columns: list) -> pd.DataFrame:\n",
    "        \"\"\"Scales the data based on the minmax or standard approach\n",
    "            Inputs:\n",
    "            self: contains attributes (refer to notes at __init__)\n",
    "            data: data to be scaled.\n",
    "            scale_columns: list of columns by label to be scaled\n",
    "            \n",
    "            Returns:\n",
    "            Pandas dataframe of the scaled data\"\"\"\n",
    "        \n",
    "        # check if minmax or standard scaler is being used\n",
    "        if (self.scaletype == \"minmax\"):\n",
    "            # for each column of the data find the minimum and maximum values:\n",
    "            for column in scale_columns:\n",
    "                # make all values in column a float\n",
    "                data[column] = data[column].astype(float)\n",
    "                \n",
    "                min_value, max_value = (data[column].min(), data[column].max())\n",
    "                column_range = max_value - min_value\n",
    "                \n",
    "                # change data using minmax equation:\n",
    "                data[column] = data[column].apply(lambda x: (x - min_value)/column_range)\n",
    "            \n",
    "            return data\n",
    "        \n",
    "        else: # must be standard due to previous assertion\n",
    "            # for each column of the data, find the mean and standard deviation\n",
    "            for column in scale_columns:\n",
    "                # make all values in column a float\n",
    "                data[column] = data[column].astype(float)\n",
    "                \n",
    "                mean, std = (data[column].mean(), data[column].std())\n",
    "                \n",
    "                # change data using standard equation:\n",
    "                data[column] = data[column].apply(lambda x: (x - mean)/std)\n",
    "            \n",
    "            return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create boolean map of columns where non-numeric columns are True, excluding items that want to be ignored\n",
    "classmap = [True, True, False, False, False, False, False, False,\n",
    "           False, False, False, False, False, False, False, True]\n",
    "\n",
    "file_directory = \"Crystal_structure.csv\"\n",
    "\n",
    "# get preprocessed data\n",
    "clean = Preprocessor(file_directory, classmap, replaceNAN = True, useScaler = True, scaletype = \"minmax\").Process()\n",
    "\n",
    "\n",
    "\n",
    "def SplitData(data: pd.DataFrame, train_ratio: float = 0.1) -> tuple:\n",
    "    \"\"\"Splits data into train and test samples\n",
    "        Inputs:\n",
    "        data: data to be split\n",
    "        train_ratio: the ratio of train to test array size for the data.\n",
    "        (defaulted to 10% train with 90% test data)\n",
    "        \n",
    "        Returns: tuple:\n",
    "                 0: pandas DataFrame of train data for independent variables.\n",
    "                 1: pandas DataFrame of test data for independent variables.\n",
    "                 2: pandas Series of train data for dependent variable.\n",
    "                 3: pandas Series of test data for dependent variable.\"\"\"\n",
    "    \n",
    "    # find index where data should be split\n",
    "    index = int(train_ratio * len(data.index))\n",
    "    \n",
    "    # Make a list of dependent and independant variables:\n",
    "    X_columns = list(data.columns)\n",
    "    y_columns = X_columns.pop(-1)\n",
    "    \n",
    "    # split X and y data into test and training data for each\n",
    "    X_train = data[X_columns][:index].reset_index(drop=True)\n",
    "    X_test = data[X_columns][index:].reset_index(drop=True)\n",
    "    y_train = data[y_columns][:index].reset_index(drop=True)\n",
    "    y_test = data[y_columns][index:].reset_index(drop=True)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = SplitData(clean)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29e808a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
